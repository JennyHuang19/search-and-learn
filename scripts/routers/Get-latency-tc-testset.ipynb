{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d72c8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b56283",
   "metadata": {},
   "source": [
    "#### Get Latencies and Token-Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90577a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def get_beam_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Split content into question blocks\n",
    "    # Each block ends with \"Total beam search time: X.XX seconds.\"\n",
    "    blocks = re.split(r'Total beam search time: \\d+\\.\\d+ seconds\\.', content)\n",
    "    \n",
    "    # Remove empty blocks and the last one (which might be incomplete)\n",
    "    blocks = [block.strip() for block in blocks if block.strip()]\n",
    "    \n",
    "    data = []\n",
    "    prev_total_tokens = 0\n",
    "    \n",
    "    for i, block in enumerate(blocks):\n",
    "        # Extract the last \"Total number of tokens generated thus far: X\" before the beam search time\n",
    "        token_matches = re.findall(r'Total number of tokens generated thus far: (\\d+)', block)\n",
    "        \n",
    "        if token_matches:\n",
    "            current_total_tokens = int(token_matches[-1])\n",
    "            \n",
    "            # Calculate tokens for this question (difference from previous)\n",
    "            beam_tc = current_total_tokens - prev_total_tokens\n",
    "            \n",
    "            # Extract beam latency from the next block's start (since we split on it)\n",
    "            if i < len(blocks) - 1:\n",
    "                # Look for the beam search time in the original content\n",
    "                # Find the position of this block in the original content\n",
    "                block_start = content.find(block)\n",
    "                block_end = block_start + len(block)\n",
    "                \n",
    "                # Look for \"Total beam search time:\" after this block\n",
    "                time_match = re.search(r'Total beam search time: (\\d+\\.\\d+) seconds\\.', content[block_end:])\n",
    "                if time_match:\n",
    "                    beam_latency = float(time_match.group(1))\n",
    "                else:\n",
    "                    beam_latency = None\n",
    "            else:\n",
    "                # For the last block, we need to look at the end of the file\n",
    "                time_match = re.search(r'Total beam search time: (\\d+\\.\\d+) seconds\\.$', content)\n",
    "                beam_latency = float(time_match.group(1)) if time_match else None\n",
    "            \n",
    "            # Question ID is 5010 + i\n",
    "            sb_idx = 5010 + i\n",
    "            \n",
    "            data.append({\n",
    "                'sb_idx': sb_idx,\n",
    "                'beam_tc': beam_tc,\n",
    "                'beam_latency': beam_latency\n",
    "            })\n",
    "            \n",
    "            prev_total_tokens = current_total_tokens\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8734d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sb_idx</th>\n",
       "      <th>beam_tc</th>\n",
       "      <th>beam_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5010</td>\n",
       "      <td>13276</td>\n",
       "      <td>30.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5011</td>\n",
       "      <td>5643</td>\n",
       "      <td>11.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5012</td>\n",
       "      <td>9461</td>\n",
       "      <td>28.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5013</td>\n",
       "      <td>3837</td>\n",
       "      <td>8.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5014</td>\n",
       "      <td>5405</td>\n",
       "      <td>12.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sb_idx  beam_tc  beam_latency\n",
       "0    5010    13276         30.93\n",
       "1    5011     5643         11.27\n",
       "2    5012     9461         28.21\n",
       "3    5013     3837          8.98\n",
       "4    5014     5405         12.53"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the file\n",
    "Beam_8_5010_5020 = get_beam_data('/dccstor/gma2/jhjenny9/search-and-learn/Beam-8-5010-5020.out')\n",
    "Beam_8_5010_5020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "365d67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def parse_beam_data_from_filename(file_path):\n",
    "    # Extract beam size and question range from filename\n",
    "    # Example: \"Beam-8-5010-5020.out\" -> beam_size=8, start=5010, end=5020\n",
    "    filename = os.path.basename(file_path)\n",
    "    match = re.match(r'Beam-(\\d+)-(\\d+)-(\\d+)\\.out', filename)\n",
    "    \n",
    "    if not match:\n",
    "        raise ValueError(f\"Invalid filename format: {filename}\")\n",
    "    \n",
    "    beam_size = int(match.group(1))\n",
    "    start_idx = int(match.group(2))\n",
    "    end_idx = int(match.group(3))\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Split content into question blocks\n",
    "    blocks = re.split(r'Total beam search time: \\d+\\.\\d+ seconds\\.', content)\n",
    "    blocks = [block.strip() for block in blocks if block.strip()]\n",
    "    \n",
    "    data = []\n",
    "    prev_total_tokens = 0\n",
    "    \n",
    "    for i, block in enumerate(blocks):\n",
    "        # Extract the last \"Total number of tokens generated thus far: X\" before the beam search time\n",
    "        token_matches = re.findall(r'Total number of tokens generated thus far: (\\d+)', block)\n",
    "        \n",
    "        if token_matches:\n",
    "            current_total_tokens = int(token_matches[-1])\n",
    "            \n",
    "            # Calculate tokens for this question (difference from previous)\n",
    "            beam_tc = current_total_tokens - prev_total_tokens\n",
    "            \n",
    "            # Extract beam latency from the next block's start\n",
    "            if i < len(blocks) - 1:\n",
    "                block_start = content.find(block)\n",
    "                block_end = block_start + len(block)\n",
    "                \n",
    "                time_match = re.search(r'Total beam search time: (\\d+\\.\\d+) seconds\\.', content[block_end:])\n",
    "                if time_match:\n",
    "                    beam_latency = float(time_match.group(1))\n",
    "                else:\n",
    "                    beam_latency = None\n",
    "            else:\n",
    "                # For the last block, look at the end of the file\n",
    "                time_match = re.search(r'Total beam search time: (\\d+\\.\\d+) seconds\\.$', content)\n",
    "                beam_latency = float(time_match.group(1)) if time_match else None\n",
    "            \n",
    "            # Question ID is start_idx + i\n",
    "            sb_idx = start_idx + i\n",
    "            \n",
    "            data.append({\n",
    "                'sb_idx': sb_idx,\n",
    "                'beam_tc': beam_tc,\n",
    "                'beam_latency': beam_latency,\n",
    "                'N': beam_size\n",
    "            })\n",
    "            \n",
    "            prev_total_tokens = current_total_tokens\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def process_all_beam_files(directory_path):\n",
    "    # Find all Beam-*.out files\n",
    "    pattern = os.path.join(directory_path, \"Beam-*.out\")\n",
    "    files = glob.glob(pattern)\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for file_path in sorted(files):\n",
    "        try:\n",
    "            df = parse_beam_data_from_filename(file_path)\n",
    "            all_data.append(df)\n",
    "            print(f\"Processed: {os.path.basename(file_path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "    if all_data:\n",
    "        # Combine all DataFrames\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b12409e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Beam-16-10000-11000.out\n",
      "Processed: Beam-16-11000-12000.out\n",
      "Processed: Beam-16-12000-13000.out\n",
      "Processed: Beam-16-13000-14000.out\n",
      "Processed: Beam-16-14000-15000.out\n",
      "Processed: Beam-16-15000-16000.out\n",
      "Processed: Beam-16-16000-17000.out\n",
      "Processed: Beam-16-17000-18000.out\n",
      "Processed: Beam-16-18000-19000.out\n",
      "Processed: Beam-16-19000-20000.out\n",
      "Processed: Beam-16-20000-21000.out\n",
      "Processed: Beam-16-21000-22000.out\n",
      "Processed: Beam-16-22000-23000.out\n",
      "Processed: Beam-16-23000-24000.out\n",
      "Processed: Beam-16-24000-25000.out\n",
      "Processed: Beam-16-25000-26000.out\n",
      "Processed: Beam-16-26000-27000.out\n",
      "Processed: Beam-16-27000-28000.out\n",
      "Processed: Beam-16-28000-29000.out\n",
      "Processed: Beam-16-29000-30000.out\n",
      "Processed: Beam-16-30000-32000.out\n",
      "Processed: Beam-16-32000-34000.out\n",
      "Processed: Beam-16-34000-36000.out\n",
      "Processed: Beam-16-36000-38000.out\n",
      "Processed: Beam-16-38000-40000.out\n",
      "Processed: Beam-16-40000-42000.out\n",
      "Processed: Beam-16-42000-44000.out\n",
      "Processed: Beam-16-44000-46000.out\n",
      "Processed: Beam-16-46000-48000.out\n",
      "Processed: Beam-16-48000-50000.out\n",
      "Processed: Beam-16-5000-6000.out\n",
      "Processed: Beam-16-6000-7000.out\n",
      "Processed: Beam-16-7000-8000.out\n",
      "Processed: Beam-16-8000-9000.out\n",
      "Processed: Beam-16-9000-10000.out\n",
      "Processed: Beam-32-10000-11000.out\n",
      "Processed: Beam-32-11000-12000.out\n",
      "Processed: Beam-32-12000-13000.out\n",
      "Processed: Beam-32-13000-14000.out\n",
      "Processed: Beam-32-14000-15000.out\n",
      "Processed: Beam-32-15000-16000.out\n",
      "Processed: Beam-32-16000-17000.out\n",
      "Processed: Beam-32-17000-18000.out\n",
      "Processed: Beam-32-18000-19000.out\n",
      "Processed: Beam-32-19000-20000.out\n",
      "Processed: Beam-32-20000-21000.out\n",
      "Processed: Beam-32-21000-22000.out\n",
      "Processed: Beam-32-22000-23000.out\n",
      "Processed: Beam-32-23000-24000.out\n",
      "Processed: Beam-32-24000-25000.out\n",
      "Processed: Beam-32-25000-26000.out\n",
      "Processed: Beam-32-26000-27000.out\n",
      "Processed: Beam-32-27000-28000.out\n",
      "Processed: Beam-32-28000-29000.out\n",
      "Processed: Beam-32-29000-30000.out\n",
      "Processed: Beam-32-5000-6000.out\n",
      "Processed: Beam-32-6000-7000.out\n",
      "Processed: Beam-32-7000-8000.out\n",
      "Processed: Beam-32-8000-9000.out\n",
      "Processed: Beam-32-9000-10000.out\n",
      "Processed: Beam-8-10000-11000.out\n",
      "Processed: Beam-8-11000-12000.out\n",
      "Processed: Beam-8-12000-13000.out\n",
      "Processed: Beam-8-13000-14000.out\n",
      "Processed: Beam-8-14000-15000.out\n",
      "Processed: Beam-8-15000-16000.out\n",
      "Processed: Beam-8-16000-17000.out\n",
      "Processed: Beam-8-17000-18000.out\n",
      "Processed: Beam-8-18000-19000.out\n",
      "Processed: Beam-8-19000-20000.out\n",
      "Processed: Beam-8-20000-21000.out\n",
      "Processed: Beam-8-21000-22000.out\n",
      "Processed: Beam-8-22000-23000.out\n",
      "Processed: Beam-8-23000-24000.out\n",
      "Processed: Beam-8-24000-25000.out\n",
      "Processed: Beam-8-25000-26000.out\n",
      "Processed: Beam-8-26000-27000.out\n",
      "Processed: Beam-8-27000-28000.out\n",
      "Processed: Beam-8-28000-29000.out\n",
      "Processed: Beam-8-29000-30000.out\n",
      "Processed: Beam-8-30000-32000.out\n",
      "Processed: Beam-8-32000-34000.out\n",
      "Processed: Beam-8-34000-36000.out\n",
      "Processed: Beam-8-36000-38000.out\n",
      "Processed: Beam-8-38000-40000.out\n",
      "Processed: Beam-8-40000-42000.out\n",
      "Processed: Beam-8-42000-44000.out\n",
      "Processed: Beam-8-44000-46000.out\n",
      "Processed: Beam-8-46000-48000.out\n",
      "Processed: Beam-8-48000-50000.out\n",
      "Processed: Beam-8-5000-6000.out\n",
      "Processed: Beam-8-5010-5020.out\n",
      "Processed: Beam-8-6000-7000.out\n",
      "Processed: Beam-8-7000-8000.out\n",
      "Processed: Beam-8-8000-9000.out\n",
      "Processed: Beam-8-9000-10000.out\n",
      "\n",
      "Combined DataFrame:\n",
      "       sb_idx  beam_tc  beam_latency   N\n",
      "0       10000    17263         24.99  16\n",
      "1       10001     4867          8.25  16\n",
      "2       10002    22265         41.00  16\n",
      "3       10003    13514         21.97  16\n",
      "4       10004    12656         18.20  16\n",
      "...       ...      ...           ...  ..\n",
      "68926    9982    19027         26.27   8\n",
      "68927    9983    50990        114.39   8\n",
      "68928    9984   119342        214.12   8\n",
      "68929    9985    45451         92.32   8\n",
      "68930    9986    87511        192.32   8\n",
      "\n",
      "[68931 rows x 4 columns]\n",
      "\n",
      "Total rows: 68931\n"
     ]
    }
   ],
   "source": [
    "# Process all files in the directory\n",
    "directory = \"/dccstor/gma2/jhjenny9/search-and-learn\"\n",
    "df = process_all_beam_files(directory)\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"\\nCombined DataFrame:\")\n",
    "    print(df)\n",
    "    print(f\"\\nTotal rows: {len(df)}\")\n",
    "else:\n",
    "    print(\"No data found or error occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04786764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">beam_latency</th>\n",
       "      <th colspan=\"2\" halign=\"left\">beam_tc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64.168285</td>\n",
       "      <td>21867</td>\n",
       "      <td>36144.985595</td>\n",
       "      <td>21867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36.347403</td>\n",
       "      <td>22890</td>\n",
       "      <td>19570.513718</td>\n",
       "      <td>22890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>77.906351</td>\n",
       "      <td>24174</td>\n",
       "      <td>44421.821378</td>\n",
       "      <td>24174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beam_latency              beam_tc       \n",
       "           mean  count          mean  count\n",
       "N                                          \n",
       "8     64.168285  21867  36144.985595  21867\n",
       "16    36.347403  22890  19570.513718  22890\n",
       "32    77.906351  24174  44421.821378  24174"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"N\")[[\"beam_latency\", \"beam_tc\"]].agg([\"mean\", \"count\"]) # debug this on a smaller dataset (N=8,16,32) to make sure the data are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2a8e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bert_features_path = \"/dccstor/gma2/jhjenny9/search-and-learn/feature-data/bert-features/16000/df_test_16000.csv\"\n",
    "bert_df = pd.read_csv(bert_features_path)\n",
    "bert_df.head()\n",
    "\n",
    "bert_df_beam = bert_df[bert_df[\"method_beam_search\"] == True]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f7e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5282, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_df_beam.shape # ask the parse_beam_data_from_filename script to only retrieve the rows where sb_idx matches one of the values in method_beam_search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35795054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6cadf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23033ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_serve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
